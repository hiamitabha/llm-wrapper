<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Wrapper - API Gateway</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            min-height: 100vh;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }
        h1 {
            color: #4a5568;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
        }
        .status {
            background: #e6fffa;
            border: 1px solid #81e6d9;
            border-radius: 8px;
            padding: 15px;
            margin: 20px 0;
            text-align: center;
        }
        .api-section {
            background: #f7fafc;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
        }
        .code-block {
            background: #2d3748;
            color: #e2e8f0;
            padding: 15px;
            border-radius: 8px;
            overflow-x: auto;
            font-family: 'Courier New', monospace;
            margin: 10px 0;
        }
        .endpoint {
            background: #edf2f7;
            border-left: 4px solid #4299e1;
            padding: 10px 15px;
            margin: 10px 0;
            border-radius: 0 8px 8px 0;
        }
        .note {
            background: #fffaf0;
            border: 1px solid #f6ad55;
            border-radius: 8px;
            padding: 15px;
            margin: 20px 0;
        }
        .features {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        .feature {
            background: #f7fafc;
            padding: 20px;
            border-radius: 8px;
            text-align: center;
        }
        .feature h3 {
            color: #2b6cb0;
            margin-bottom: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üöÄ LLM Wrapper API Gateway</h1>
        
        <div class="status">
            <strong>‚úÖ Server Status: Running</strong><br>
            Welcome to the LLM Wrapper API Gateway. This service routes your LLM inference requests to various cloud providers.
        </div>



        <div class="api-section">
            <h2>üì° API Endpoint</h2>
            <div class="endpoint">
                <strong>POST /v1/chat/completions</strong>
            </div>
            <p>This endpoint accepts OpenAI-compatible chat completion requests and routes them to configured LLM providers.</p>
        </div>

        <div class="api-section">
            <h2>üîß Sample API Request</h2>
            <p>Here's how to make a request to the LLM Wrapper:</p>
            
            <div class="code-block">
curl -X POST "http://knowledge.learnwitharobot.com/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN_HERE" \
  -d '{
    "model": "grok-4-latest",
    "messages": [
      {
        "role": "user",
        "content": "Hello, how are you today?"
      }
    ],
    "max_tokens": 100,
    "temperature": 0.7
  }'
            </div>
        </div>

        <div class="api-section">
            <h2>üìã Request Format</h2>
            <p>The API accepts standard OpenAI-compatible requests with the following structure:</p>
            
            <div class="code-block">
{
  "model": "model-name",
  "messages": [
    {"role": "user", "content": "Your message here"}
  ],
  "max_tokens": 100,
  "temperature": 0.7,
  "stream": false
}
            </div>
        </div>

        <div class="api-section">
            <h2>üîê Authentication</h2>
            <p>All requests must include a valid Bearer token in the Authorization header:</p>
            <div class="code-block">
Authorization: Bearer YOUR_TOKEN_HERE
            </div>
            <p>Tokens can be managed using the <code>tokens/manage_tokens.py</code> script.</p>
        </div>

        <div class="note">
            <strong>üí° Note:</strong> This is a proxy service that routes your requests to various LLM providers. 
            Make sure you have valid API keys configured in your environment variables and that your tokens 
            are properly set up with appropriate rate limits.
        </div>

        <div class="api-section">
            <h2>üìä Available Models</h2>
            <p>Supported models depend on your configuration. Common models include:</p>
            <ul>
                <li><strong>XAI:</strong> grok-4-latest, grok-3-latest, grok-3-fast-latest</li>
                <li><strong>Perplexity:</strong> sonar, sonar-pro, sonar-deep-research</li>
                <li><strong>Sambanova:</strong> Meta-Llama-3.3-70B-Instruct</li>
            </ul>
        </div>

        <div class="api-section">
            <h2>üö® Error Codes</h2>
            <ul>
                <li><strong>401:</strong> Invalid or expired authorization token</li>
                <li><strong>429:</strong> Rate limit exceeded</li>
                <li><strong>400:</strong> Invalid request format or unsupported model</li>
                <li><strong>500:</strong> Internal server error</li>
            </ul>
        </div>
    </div>
</body>
</html> 